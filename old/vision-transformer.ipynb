{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:24.167817Z","iopub.status.busy":"2024-03-04T20:48:24.166969Z","iopub.status.idle":"2024-03-04T20:48:24.174881Z","shell.execute_reply":"2024-03-04T20:48:24.173824Z","shell.execute_reply.started":"2024-03-04T20:48:24.167784Z"},"id":"HtP0TWi8fm7m","trusted":true},"outputs":[],"source":["import torch\n","from datasets import load_dataset\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from huggingface_hub import login\n","import requests\n","from PIL import Image\n","from transformers import VisionEncoderDecoderModel, ViTImageProcessor, GPT2TokenizerFast\n","from tqdm import tqdm\n","from IPython.display import display\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.manual_seed(199)\n","np.random.seed(199)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-04T20:48:24.176949Z","iopub.status.busy":"2024-03-04T20:48:24.176666Z","iopub.status.idle":"2024-03-04T20:48:28.394758Z","shell.execute_reply":"2024-03-04T20:48:28.394021Z","shell.execute_reply.started":"2024-03-04T20:48:24.176925Z"},"id":"Q476D3hjQuix","outputId":"fc237d5e-df98-4d3b-f0b0-4b3ea18e7420","trusted":true},"outputs":[],"source":["dataset_train = load_dataset(\"martinsinnona/visdecode\", split = \"train\")\n","dataset_test = load_dataset(\"martinsinnona/visdecode\", split = \"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:28.396535Z","iopub.status.busy":"2024-03-04T20:48:28.395894Z","iopub.status.idle":"2024-03-04T20:48:28.401568Z","shell.execute_reply":"2024-03-04T20:48:28.400479Z","shell.execute_reply.started":"2024-03-04T20:48:28.396504Z"},"trusted":true},"outputs":[],"source":["print(dataset_train, dataset_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:28.403008Z","iopub.status.busy":"2024-03-04T20:48:28.402708Z","iopub.status.idle":"2024-03-04T20:48:34.651219Z","shell.execute_reply":"2024-03-04T20:48:34.650246Z","shell.execute_reply.started":"2024-03-04T20:48:28.402957Z"},"trusted":true},"outputs":[],"source":["# Loading a fine-tuned image captioning Transformer Model\n","\n","# ViT Encoder - Decoder Model\n","model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").to(device)\n","\n","# Corresponding ViT Tokenizer\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n","\n","# Image processor\n","image_processor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:34.653996Z","iopub.status.busy":"2024-03-04T20:48:34.653662Z","iopub.status.idle":"2024-03-04T20:48:34.660667Z","shell.execute_reply":"2024-03-04T20:48:34.659626Z","shell.execute_reply.started":"2024-03-04T20:48:34.653948Z"},"trusted":true},"outputs":[],"source":["# Accesssing images from the web\n","import urllib.parse as parse\n","import os\n","# Verify url\n","def check_url(string):\n","    try:\n","        result = parse.urlparse(string)\n","        return all([result.scheme, result.netloc, result.path])\n","    except:\n","        return False\n","\n","# Load an image\n","def load_image(image_path):\n","    if check_url(image_path):\n","        return Image.open(requests.get(image_path, stream=True).raw)\n","    elif os.path.exists(image_path):\n","        return Image.open(image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:34.662218Z","iopub.status.busy":"2024-03-04T20:48:34.661826Z","iopub.status.idle":"2024-03-04T20:48:34.675428Z","shell.execute_reply":"2024-03-04T20:48:34.674630Z","shell.execute_reply.started":"2024-03-04T20:48:34.662192Z"},"trusted":true},"outputs":[],"source":["# Image inference\n","def get_caption_from_url(model, image_processor, tokenizer, image_path):\n","    \n","    image = load_image(image_path)\n","    return get_caption(model, image_processor, tokenizer, image)\n","    \n","\n","def get_caption(model, image_processor, tokenizer, image):\n","    \n","    img = image_processor(image, return_tensors=\"pt\").to(device)\n","    \n","    # Generating captions\n","    output = model.generate(**img)\n","    #print(\"tokens:\",output)\n","\n","    # decode the output\n","    caption = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n","\n","    return caption"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:34.676663Z","iopub.status.busy":"2024-03-04T20:48:34.676375Z","iopub.status.idle":"2024-03-04T20:48:35.213935Z","shell.execute_reply":"2024-03-04T20:48:35.212967Z","shell.execute_reply.started":"2024-03-04T20:48:34.676639Z"},"trusted":true},"outputs":[],"source":["# Loading URLs\n","url = \"https://images.pexels.com/photos/101667/pexels-photo-101667.jpeg?auto=compress&cs=tinysrgb&w=600\"\n","# Display Image\n","display(load_image(url))\n","\n","# Display Caption\n","get_caption_from_url(model, image_processor, tokenizer, url)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T20:48:35.215280Z","iopub.status.busy":"2024-03-04T20:48:35.215001Z","iopub.status.idle":"2024-03-04T20:48:41.229561Z","shell.execute_reply":"2024-03-04T20:48:41.228719Z","shell.execute_reply.started":"2024-03-04T20:48:35.215255Z"},"trusted":true},"outputs":[],"source":["model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T21:13:51.846356Z","iopub.status.busy":"2024-03-04T21:13:51.845648Z","iopub.status.idle":"2024-03-04T21:35:12.271099Z","shell.execute_reply":"2024-03-04T21:35:12.270156Z","shell.execute_reply.started":"2024-03-04T21:13:51.846322Z"},"trusted":true},"outputs":[],"source":["epochs = 10\n","losses = []\n","batch_loss = 0\n","\n","model.to(device)\n","model.train()\n","\n","for epoch in range(epochs):\n","    for index, image in enumerate(dataset_train):\n","        \n","        if index % 50 == 0: print(index, \" /\", len(dataset_train))\n","\n","        # Preprocessing the Image\n","        \n","        pixels = image_processor(image['image'].convert(\"RGB\"), return_tensors=\"pt\").to(device)\n","        \n","        stop = image['text'].find(\"</field>\", 37)\n","        target_text = image['text'][64+7:stop] + \"<|endoftext|>\"\n","        \n","        target_sequence = tokenizer(target_text, return_tensors=\"pt\", padding=True).input_ids.to(device)\n","        \n","        # Generating captions\n","        output = model(pixel_values=pixels['pixel_values'], labels=target_sequence)\n","\n","        # Compute the loss\n","        loss = output.loss\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        \n","        batch_loss += loss.cpu().detach().numpy().item()\n","        \n","    batch_loss = batch_loss / len(dataset_train)\n","    \n","    print(\"Epoch: \", epoch, \" | batch mean loss:\", batch_loss)\n","    losses.append(batch_loss)\n","    \n","    batch_loss = 0\n","    \n","plt.plot(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T21:35:37.953010Z","iopub.status.busy":"2024-03-04T21:35:37.952065Z","iopub.status.idle":"2024-03-04T21:35:38.957289Z","shell.execute_reply":"2024-03-04T21:35:38.956336Z","shell.execute_reply.started":"2024-03-04T21:35:37.952961Z"},"trusted":true},"outputs":[],"source":["for index, data in enumerate(dataset_test):\n","    print(get_caption(model, image_processor, tokenizer, data['image'].convert(\"RGB\")))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T21:35:44.504678Z","iopub.status.busy":"2024-03-04T21:35:44.504253Z","iopub.status.idle":"2024-03-04T21:35:44.614763Z","shell.execute_reply":"2024-03-04T21:35:44.613894Z","shell.execute_reply.started":"2024-03-04T21:35:44.504643Z"},"trusted":true},"outputs":[],"source":["print(get_caption(model, image_processor, tokenizer, dataset_train[0]['image'].convert(\"RGB\")))\n","dataset_train[0]['image']"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30512,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
